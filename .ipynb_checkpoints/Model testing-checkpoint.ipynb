{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9c8ec31d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a5890b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the pickled binfiles\n",
    "with open('Data/Bin files/scaler.pkl', 'rb') as file:\n",
    "    scaler = pickle.load(file)\n",
    "\n",
    "model = tf.keras.models.load_model('Data/Bin files/Custom model 2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4ffc9e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constructing a custom transformer for resizing images\n",
    "class ResizeTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        self.cv2 = __import__('cv2')\n",
    "        self.dim = (72, 72)\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        X = self.cv2.cvtColor(X, self.cv2.COLOR_BGR2GRAY)\n",
    "        X = self.cv2.resize(X, self.dim, interpolation=self.cv2.INTER_AREA)\n",
    "        X = X.reshape(1, -1)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "16ed5da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constructing a custom transformer for resizing images\n",
    "class CategoryPredictor(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self,model):\n",
    "        self.model = model\n",
    "        self.labels = ['Hoodie/Sweatshirt', 'Jeans', 'Leather Jacket', 'Pants', 'Raincoat', 'Shorts', 'Sleepwear',\n",
    "                       'Socks',\n",
    "                       'Suits/Blazers', 'Sweater']\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self.model\n",
    "\n",
    "    def predict(self, X, y=None):\n",
    "        prediction = self.model.predict_classes(X)\n",
    "        return self.labels[prediction[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f26ed70f",
   "metadata": {},
   "outputs": [],
   "source": [
    "resize_trans = ResizeTransformer()\n",
    "predictor = CategoryPredictor(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "227f9933",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model pipeline\n",
    "model_pipeline = Pipeline([('resize_trans', resize_trans), ('scaler', scaler),\n",
    "                            ('predictor', predictor)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "75878728",
   "metadata": {},
   "outputs": [],
   "source": [
    "def shortlist_images(category):\n",
    "    # DB connection for loading data\n",
    "    db_connection = sqlite3.connect('Data/Database/job_database.db')\n",
    "    query = f\"SELECT img_src FROM product_info WHERE type = '{category}'\"\n",
    "    product_df = pd.read_sql_query(query, db_connection)\n",
    "    db_connection.close()\n",
    "    return product_df\n",
    "\n",
    "\n",
    "def similar_images(img_src, compare_image):\n",
    "    # Dict to store similarity\n",
    "    image_similarity = {}\n",
    "    # Iterate through images\n",
    "    dim = (72, 72)\n",
    "    compare_image = cv2.cvtColor(compare_image, cv2.COLOR_BGR2RGB)\n",
    "    compare_image = cv2.resize(compare_image, dim, interpolation=cv2.INTER_AREA)\n",
    "    compare_image = compare_image.reshape(-1)\n",
    "    for img in img_src['img_src']:\n",
    "        file_name = img.split('/')[-1]\n",
    "        path = f'Data/Images/{file_name}'\n",
    "        image = cv2.imread(path)\n",
    "        try:\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "        # Resize the image\n",
    "        image = cv2.resize(image, dim, interpolation=cv2.INTER_AREA)\n",
    "        image = image.reshape(-1)\n",
    "        image_similarity[img] = structural_similarity(compare_image, image)\n",
    "\n",
    "    return image_similarity\n",
    "\n",
    "\n",
    "def find_similar_products(product_type, image):\n",
    "    # Write as df\n",
    "    similarity_score = similar_images(shortlist_images(product_type), image)\n",
    "    similarity_df = pd.DataFrame(similarity_score.items(), columns=['img_src', 'sim_score'])\n",
    "    # Read all the data\n",
    "    # DB connection for loading data\n",
    "    db_connection = sqlite3.connect('Data/Database/job_database.db')\n",
    "    query = f\"SELECT link,img_src FROM product_info WHERE type = '{product_type}'\"\n",
    "    product_df = pd.read_sql_query(query, db_connection)\n",
    "    db_connection.close()\n",
    "\n",
    "    similarity_df = similarity_df.sort_values(by=['sim_score'], ascending=False).head(5)\n",
    "    return similarity_df.merge(product_df, on=['img_src'])\n",
    "\n",
    "\n",
    "def cosine_similarity(similar_images_df):\n",
    "    cosine_df = pd.read_csv('Data/Bin files/cosine_similarity.csv', index_col=0)\n",
    "    similar_index = set(similar_images_df['link'])\n",
    "    for index, row in similar_images_df.iterrows():\n",
    "\n",
    "        if len(similar_index) >= 10:\n",
    "            break\n",
    "        index_sim_prod = cosine_df[cosine_df[row['link']] > 0.8][row['link']].index\n",
    "\n",
    "        for idx in index_sim_prod:\n",
    "            if len(similar_index) != 10:\n",
    "                similar_index.add(idx)\n",
    "\n",
    "    return similar_index\n",
    "\n",
    "\n",
    "def recommend_products(image, model_pipeline):\n",
    "    # Predict the type of product\n",
    "    product_type = model_pipeline.predict(image)\n",
    "    similar_images_df = find_similar_products(product_type, image)\n",
    "    similar_links = cosine_similarity(similar_images_df)\n",
    "    return similar_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "06ecacdf",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "X has 15552 features, but MinMaxScaler is expecting 5184 features as input.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-39-82bc893100f4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mimage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'upload/temp.jpg'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mrecommended_products\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrecommend_products\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel_pipeline\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-38-8fedd532ea6c>\u001b[0m in \u001b[0;36mrecommend_products\u001b[1;34m(image, model_pipeline)\u001b[0m\n\u001b[0;32m     66\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mrecommend_products\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel_pipeline\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m     \u001b[1;31m# Predict the type of product\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 68\u001b[1;33m     \u001b[0mproduct_type\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel_pipeline\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     69\u001b[0m     \u001b[0msimilar_images_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfind_similar_products\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mproduct_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m     \u001b[0msimilar_links\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcosine_similarity\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msimilar_images_df\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\metaestimators.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    118\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    119\u001b[0m         \u001b[1;31m# lambda, but not partial, allows help() to work with update_wrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 120\u001b[1;33m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    121\u001b[0m         \u001b[1;31m# update the docstring of the returned function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    122\u001b[0m         \u001b[0mupdate_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X, **predict_params)\u001b[0m\n\u001b[0;32m    416\u001b[0m         \u001b[0mXt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    417\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtransform\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwith_final\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 418\u001b[1;33m             \u001b[0mXt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtransform\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    419\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mpredict_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    420\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py\u001b[0m in \u001b[0;36mtransform\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    432\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    433\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 434\u001b[1;33m         X = self._validate_data(X, copy=self.copy, dtype=FLOAT_DTYPES,\n\u001b[0m\u001b[0;32m    435\u001b[0m                                 force_all_finite=\"allow-nan\", reset=False)\n\u001b[0;32m    436\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    435\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    436\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcheck_params\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'ensure_2d'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 437\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_n_features\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    438\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    439\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m_check_n_features\u001b[1;34m(self, X, reset)\u001b[0m\n\u001b[0;32m    363\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    364\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mn_features\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_features_in_\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 365\u001b[1;33m             raise ValueError(\n\u001b[0m\u001b[0;32m    366\u001b[0m                 \u001b[1;34mf\"X has {n_features} features, but {self.__class__.__name__} \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    367\u001b[0m                 f\"is expecting {self.n_features_in_} features as input.\")\n",
      "\u001b[1;31mValueError\u001b[0m: X has 15552 features, but MinMaxScaler is expecting 5184 features as input."
     ]
    }
   ],
   "source": [
    "image = cv2.imread('upload/temp.jpg')\n",
    "recommended_products = recommend_products(image, model_pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28a4e5e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_pipeline.predict(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "38ed58b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1492, 679, 3)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dd369244",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate\n",
    "with open('upload/product_link.txt', 'wb') as file:\n",
    "     for link in recommended_products:\n",
    "            link = link + '\\n'\n",
    "            file.write(link.encode())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
